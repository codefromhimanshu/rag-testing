# RAG Model Test Project

This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app). The purpose of this project is to create test code for a Retrieval-Augmented Generation (RAG) model. This model is designed to search the internet and utilize AI, specifically using the LangChain library, to summarize the findings.

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

# Project Overview

## Introduction

This project uses `next/font` to automatically optimize and load Inter, a custom Google Font.

## Project Technologies

The test code incorporates several technologies:

- **Tailwind CSS**: For utility-first styling.
- **NextAuth.js**: For authentication workflows.
- **Sequelize ORM**: A promise-based Node.js ORM for database management.
- **Bcrypt**: For secure password hashing.
- **Cheerio**: For server-side DOM manipulation and web scraping.
- **LangChain**: For building applications with language models.
- **pg (PostgreSQL client for Node.js)**: For interfacing with the PostgreSQL database.

## Learn More

To learn more about Next.js:

- [Next.js Documentation](https://nextjs.org/docs) - Learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - An interactive Next.js tutorial.
- [Next.js GitHub repository](https://github.com/vercel/next.js) - Feedback and contributions are welcome!

## Deployment

The easiest way to deploy your Next.js app is to use the Vercel Platform from the creators of Next.js. Check out the [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.

## Project Purpose

The aim of this project is to demonstrate a RAG model's ability to perform internet searches and summarize the results. By integrating various technologies such as Tailwind CSS, NextAuth, Sequelize ORM, bcrypt, Cheerio, LangChain, and pg, this project sets the foundation for developing applications that can process and condense large volumes of data into digestible summaries.
